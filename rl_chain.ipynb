{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MealPlanner:\n",
    "    def __init__(self, name: str, desc: str, difficulty: str, tags: str):\n",
    "        try:\n",
    "            self.name = name\n",
    "            self.desc = desc\n",
    "            self.diff = difficulty\n",
    "            self.tags = tags\n",
    "        except:\n",
    "            print(name)\n",
    "            raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actions\n",
    "## examples copied from hello fresh website\n",
    "actions = []\n",
    "actions.append(MealPlanner(name=\"One-Pan Beef Enchiladas Verdes with Mexican Cheese Blend & Hot Sauce Crema\", difficulty=\"Easy\", tags=\"Spicy, Easy Cleanup, Easy Prep\", desc=\"When it comes to Mexican-style cuisine, burritos typically get all the glory. In our humble opinion, enchiladas are an unsung dinner hero. They’re technically easier-to-assemble burritos that get smothered in a delicious sauce, but they’re really so much more than that! Ours start with spiced beef and charred green pepper that get rolled up in warm tortillas. This winning combo gets topped with tangy salsa verde and cheese, then baked until bubbly and melty. Hear that? That’s the sound of the dinner bell!\"))\n",
    "actions.append(MealPlanner(name=\"Chicken & Mushroom Flatbreads with Gouda Cream Sauce & Parmesan\", difficulty=\"Easy\", tags=\"\", desc=\"Yes we love our simple cheese pizza with red sauce but tonight, move over, marinara—there’s a new sauce in town. In this recipe, crispy flatbreads are slathered with a rich, creamy gouda-mustard sauce we just can’t get enough of. We top that off with a pile of caramelized onion and earthy cremini mushrooms. Shower with Parmesan, and that’s it. Simple, satisfying, and all in 30 minutes–a dinner idea you can’t pass up!\"))\n",
    "actions.append(MealPlanner(name=\"Sweet Potato & Pepper Quesadillas with Southwest Crema & Tomato Salsa\", difficulty=\"Easy\", tags=\"Veggie\", desc=\"This quesadilla is jam-packed with flavorful roasted sweet potato and green pepper, plus two types of gooey, melty cheese (how could we choose just one?!). Of course, we’d never forget the toppings—there’s a fresh tomato salsa and dollops of spiced lime crema. Now for the fun part: piling on a little bit of everything to construct the perfect bite!\"))\n",
    "actions.append(MealPlanner(name=\"One-Pan Trattoria Tortelloni Bake with a Crispy Parmesan Panko Topping\", difficulty=\"Easy\", tags=\"Veggie, Easy Cleanup, Easy Prep\", desc=\"Think a cheesy stuffed pasta can’t get any better? What about baking it in a creamy sauce with a crispy topping? In this recipe, we toss cheese-stuffed tortelloni in an herby tomato cream sauce, then top with Parmesan and panko breadcrumbs. Once broiled, it turns into a showstopping topping that’ll earn you plenty of oohs and aahs from your lucky fellow diners.\"))\n",
    "\n",
    "meals = []\n",
    "for action in actions:\n",
    "    action_str = \"title=\" + action.name + \" description=\" + action.desc + \" tags=\" + action.tags\n",
    "    action_str = action_str.replace(\":\", \"\")\n",
    "    action_str = action_str.replace(\"|\", \"\")\n",
    "    meals.append(action_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "import langchain\n",
    "langchain.debug = False\n",
    "# assuming LLM api keys have been set in the environment\n",
    "# can use whatever LLM you want here doesn't have to be AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    temperature=0,\n",
    "    request_timeout=10,\n",
    "    max_retries=1,\n",
    "    client=None,\n",
    ")\n",
    "\n",
    "llm.predict('Are you ready?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### default chain default reward (the LLM is used to judge and rank the response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rl_chain\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_PROMPT_TEMPLATE = \"\"\"Here is the description of a meal: {meal}.\n",
    "\n",
    "You have to embed this into the given text where it makes sense. Here is the given text: {text_to_personalize}.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"meal\", \"text_to_personalize\"], template=_PROMPT_TEMPLATE\n",
    ")\n",
    "\n",
    "chain = rl_chain.pick_best_chain.PickBest.from_llm(\n",
    "    llm=llm,\n",
    "    prompt=PROMPT,\n",
    "    response_validator = rl_chain.pick_best_chain.AutoValidatePickBest(llm=llm),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is recommended to embedd the action features and the context feature\n",
    "\n",
    "for _ in range(3):\n",
    "    response = chain.run(User = rl_chain.BasedOn(rl_chain.Embed(\"Tom\")),\n",
    "    preference = rl_chain.BasedOn(rl_chain.Embed(\"Vegetarian, regular dairy is ok\")),\n",
    "    text_to_personalize = \"This is the weeks specialty dish, our master chefs believe you will love it!\",\n",
    "    meal = rl_chain.Embed(rl_chain.ToSelectFrom(meals)))\n",
    "\n",
    "    print(response[\"response\"])\n",
    "    rr = response[\"response_result\"]\n",
    "    print(f\"cost: {rr.label.cost}, action: {rr.chosen_action}, probability: {rr.chosen_action_probability}, \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_OTHER_PROMPT_TEMPLATE = \"\"\"You can use the actions that were chosen by VW like so: {action}.\n",
    "\n",
    "And use whatever other vars you want to pass into the chain at run: {some_text}. And {some_other_text}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "OTHER_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"action\", \"some_text\", \"some_other_text\"],\n",
    "    template=_OTHER_PROMPT_TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rl_chain.pick_best_chain\n",
    "\n",
    "chain = rl_chain.pick_best_chain.PickBest.from_llm(\n",
    "    llm=llm,\n",
    "    model_save_dir=\"./models\",  # where to save the model checkpoints\n",
    "    prompt=OTHER_PROMPT,\n",
    "    response_validator = rl_chain.pick_best_chain.AutoValidatePickBest(llm=llm)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.run(\n",
    "    some_text = \"This is some text\",\n",
    "    some_other_text = \"This is some other text\",\n",
    "    action=rl_chain.ToSelectFrom([\"an action\", \"another action\", \"a third action\"]),\n",
    "    User = rl_chain.BasedOn(\"Tom\"),\n",
    "    preference = rl_chain.BasedOn(\"Vegetarian\")\n",
    ")\n",
    "\n",
    "print(response[\"response\"])\n",
    "rr = response[\"response_result\"]\n",
    "print(f\"cost: {rr.cost}, action: {rr.chosen_action}, probability: {rr.chosen_action_probability}, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### actions and context with multiple namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each action is a dictionary of namespace to action string\n",
    "# this example here shows that while embedding is recommended for all features, it is not required and can be customized\n",
    "action_strs_w_ns = [{\"A\":\"an action feature\", \"B\" : rl_chain.Embed(\"antoher action feature\")}, {\"B\": \"another action\"}, {\"C\":\"a third action\"}]\n",
    "\n",
    "inputs = {\n",
    "    \"some_text\": \"This is some text\",\n",
    "    \"some_other_text\": \"This is some other text\",\n",
    "    \"action\" : rl_chain.ToSelectFrom(action_strs_w_ns)\n",
    "}\n",
    "\n",
    "inputs[\"User\"] = rl_chain.BasedOn(\"Tom\")\n",
    "inputs[\"preference\"] = rl_chain.BasedOn(rl_chain.Embed(\"Vegetarian\"))\n",
    "response = chain.run(inputs)\n",
    "print(response[\"response\"])\n",
    "rr = response[\"response_result\"]\n",
    "print(f\"cost: {rr.cost}, action: {rr.chosen_action}, probability: {rr.chosen_action_probability}, \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store a checkpoint to the file (overriding existing checkpoint until the chain is restarted)\n",
    "chain.save_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### chain with default prompt and custom reward prompt (the LLM is used to judge and rank the response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "human_template = \"Given {preference} rank how good or bad this selection is {action}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    human_template\n",
    ")\n",
    "\n",
    "REWARD_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [rl_chain.pick_best_chain.AutoValidatePickBest.default_system_prompt, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rl_chain\n",
    "\n",
    "chain = rl_chain.pick_best_chain.PickBest.from_llm(\n",
    "    llm=llm,\n",
    "    prompt=OTHER_PROMPT,\n",
    "    model_save_dir=\"./models\",  # where to save the model checkpoints\n",
    "    response_validator=rl_chain.pick_best_chain.AutoValidatePickBest(llm=llm, prompt=REWARD_PROMPT),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\"an action\", \"another action\", \"a third action\"]\n",
    "\n",
    "response = chain.run(\n",
    "    some_text = \"Some text\",\n",
    "    some_other_text = \"Some other text\",\n",
    "    action=rl_chain.ToSelectFrom(actions),\n",
    "    User = rl_chain.BasedOn(\"Tom\"),\n",
    "    preference = rl_chain.BasedOn(\"Vegetarian\"),\n",
    ")\n",
    "print(response[\"response\"])\n",
    "rr = response[\"response_result\"]\n",
    "print(f\"cost: {rr.cost}, action: {rr.chosen_action}, probability: {rr.chosen_action_probability}, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### other reward options\n",
    "\n",
    "custom reward class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom reward class/function is just defining another class that inherits from RewardChecker and implementing the grade_response method\n",
    "import rl_chain\n",
    "\n",
    "class CustomResponseValidator(rl_chain.ResponseValidator):\n",
    "    def grade_response(\n",
    "        self, inputs, llm_response: str\n",
    "    ) -> float:\n",
    "        # do whatever you want here, use whatever inputs you supplied and return reward\n",
    "        reward = 1.0\n",
    "        return reward\n",
    "    \n",
    "# set this in the chain during construction (response_validator=CustomResponseValidator()) and it will be auto-called"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asynchronus user defined reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rl_chain\n",
    "\n",
    "chain = rl_chain.pick_best_chain.PickBest.from_llm(\n",
    "    llm=llm,\n",
    "    prompt=PROMPT)\n",
    "\n",
    "# whenever you have the reward for the call, send it back to the chain to learn from\n",
    "\n",
    "response = chain.run(text_to_personalize = \"This is the weeks specialty dish, our master chefs believe you will love it!\",\n",
    "                     meal = rl_chain.ToSelectFrom(meals),\n",
    "                     User = rl_chain.BasedOn(rl_chain.Embed(\"Tom\")),\n",
    "                     preference = rl_chain.BasedOn(\"Vegetarian\")\n",
    "                    )\n",
    "print(response[\"response\"])\n",
    "rr = response[\"response_result\"]\n",
    "# cost should be None here because we turned auto-checkin off\n",
    "print(f\"cost: {rr.cost}, action: {rr.chosen_action}, probability: {rr.chosen_action_probability}, \")\n",
    "chain.learn_delayed_reward(reward=1.0, response_result=rr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
