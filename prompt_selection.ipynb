{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare core llm chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As an AI language model, I am always ready to assist you. How may I help you today?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug = False # set to True if  you want to see what the LLM is doing\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    temperature=0,\n",
    "    request_timeout=20,\n",
    "    max_retries=1,\n",
    "    client=None,\n",
    ")\n",
    "\n",
    "llm.predict('Are you ready?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"adjective\", \"content\", \"topic\"],\n",
    "        template=\"Hi, please create {adjective} {content} about {topic}.\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the world of tech, there's a new king\\nAnd his name is Machine Learning\\nHe's smart, he's quick, he's always learning\\nAnd he's got us all yearning\\n\\nFor the day when he'll take over\\nAnd we'll all be his loyal rover\\nHe'll make decisions with precision\\nAnd we'll all be in submission\\n\\nBut until that day arrives\\nWe'll keep feeding him data and files\\nWe'll teach him how to think and reason\\nAnd he'll keep getting smarter each season\\n\\nSo let's raise a glass to Machine Learning\\nThe future is bright, it's not concerning\\nWe'll all be living in a world of ease\\nThanks to our friend, Machine Learning, please!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.run(\n",
    "    adjective = \"funny\",\n",
    "    content = \"poem\",\n",
    "    topic = \"machine learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 11:10:39,895 - rl_chain.rl_chain_base - WARNING - No response validator provided. This is not recommended for RLChains.\n",
      "2023-08-15 11:10:53,019 - rl_chain.rl_chain_base - INFO - learning from scratch\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\ataymano\\AppData\\Local\\Temp\\ipykernel_6820\\2359233398.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">rl_chain</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">langchain.prompts.prompt</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> PromptTemplate                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>4 llm_chain = rl_chain.slates_chain.SlatesPersonalizerChain.from_llm(                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 │   </span>llm=llm,                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 │   </span>prompt = PromptTemplate(                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7 │   │   </span>input_variables=[<span style=\"color: #808000; text-decoration-color: #808000\">\"adjective\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"content\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"topic\"</span>],                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\slates_chain.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">288</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_llm</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">285 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@classmethod</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">286 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_llm</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, llm: BaseLanguageModel, prompt: PromptTemplate, **kwargs: Any):      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">287 │   │   </span>llm_chain = LLMChain(llm=llm, prompt=prompt)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>288 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> SlatesPersonalizerChain.from_chain(                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">289 │   │   │   </span>llm_chain=llm_chain, prompt=prompt, **kwargs                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">290 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">291 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\slates_chain.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">283</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_chain</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">280 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@classmethod</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_chain</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, llm_chain: Chain, prompt: PromptTemplate, **kwargs: Any):          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>283 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> SlatesPersonalizerChain(llm_chain=llm_chain, prompt=prompt, **kwargs)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">284 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">285 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@classmethod</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">286 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_llm</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, llm: BaseLanguageModel, prompt: PromptTemplate, **kwargs: Any):      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\slates_chain.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">219</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">216 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> text_embedder <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">217 │   │   │   </span>text_embedder = SlatesTextEmbedder()                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">218 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>219 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(text_embedder=text_embedder, *args, **kwargs)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">220 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">call_before_predict</span>(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">222 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs: Dict[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, Any]                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\rl_chain_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">236</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">233 │   │   │   </span>workspace=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model_repo.load(vw_cmd <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> []),                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">234 │   │   │   </span>text_embedder=text_embedder,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">235 │   │   │   </span>logger=VwLogger(vw_logs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>236 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">237 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">Config</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Configuration for this pydantic object.\"\"\"</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\model_repository.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">38</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">35 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.logger.info(<span style=\"color: #808000; text-decoration-color: #808000\">f'model is loaded from: {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model_path<span style=\"color: #808000; text-decoration-color: #808000\">}'</span>)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">36 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> vw.Workspace(commandline, model_data=model_data)                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.logger.info(<span style=\"color: #808000; text-decoration-color: #808000\">f'learning from scratch'</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>38 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> vw.Workspace(commandline)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\ataymano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\Loca</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">lCache\\local-packages\\Python310\\site-packages\\vowpalwabbit\\pyvw.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">465</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 462 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._log_fwd = _log_forward()                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 463 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._log_wrapper = pylibvw.vw_log(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._log_fwd)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 464 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 465 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>merged_arg_list = _build_command_line(arg_str, arg_list, **kw)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 466 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._log_wrapper:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 467 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(merged_arg_list, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._log_wrapper)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 468 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\ataymano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\Loca</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">lCache\\local-packages\\Python310\\site-packages\\vowpalwabbit\\pyvw.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">408</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_build_command_line</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 405 │   </span>merged_arg_list = []                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 406 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> arg_str <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 407 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(arg_str, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 408 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"arg_str must be a string\"</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 409 │   │   # Maintain old behavior of space split strings</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 │   │   </span>merged_arg_list.extend(arg_str.split())                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 411 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>arg_str must be a string\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\ataymano\\AppData\\Local\\Temp\\ipykernel_6820\\2359233398.py\u001b[0m:\u001b[94m4\u001b[0m in \u001b[92m<module>\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mrl_chain\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mlangchain\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mprompts\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mprompt\u001b[0m \u001b[94mimport\u001b[0m PromptTemplate                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m4 llm_chain = rl_chain.slates_chain.SlatesPersonalizerChain.from_llm(                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[2m│   \u001b[0mllm=llm,                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[2m│   \u001b[0mprompt = PromptTemplate(                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   │   \u001b[0minput_variables=[\u001b[33m\"\u001b[0m\u001b[33madjective\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mcontent\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mtopic\u001b[0m\u001b[33m\"\u001b[0m],                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\slates_chain.py\u001b[0m:\u001b[94m288\u001b[0m in \u001b[92mfrom_llm\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m285 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@classmethod\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m286 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfrom_llm\u001b[0m(\u001b[96mcls\u001b[0m, llm: BaseLanguageModel, prompt: PromptTemplate, **kwargs: Any):      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m287 \u001b[0m\u001b[2m│   │   \u001b[0mllm_chain = LLMChain(llm=llm, prompt=prompt)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m288 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m SlatesPersonalizerChain.from_chain(                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   │   │   \u001b[0mllm_chain=llm_chain, prompt=prompt, **kwargs                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m291 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\slates_chain.py\u001b[0m:\u001b[94m283\u001b[0m in \u001b[92mfrom_chain\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m280 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@classmethod\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfrom_chain\u001b[0m(\u001b[96mcls\u001b[0m, llm_chain: Chain, prompt: PromptTemplate, **kwargs: Any):          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m283 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m SlatesPersonalizerChain(llm_chain=llm_chain, prompt=prompt, **kwargs)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m284 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m285 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@classmethod\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m286 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mfrom_llm\u001b[0m(\u001b[96mcls\u001b[0m, llm: BaseLanguageModel, prompt: PromptTemplate, **kwargs: Any):      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\slates_chain.py\u001b[0m:\u001b[94m219\u001b[0m in \u001b[92m__init__\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m216 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m text_embedder \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m217 \u001b[0m\u001b[2m│   │   │   \u001b[0mtext_embedder = SlatesTextEmbedder()                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m218 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m219 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(text_embedder=text_embedder, *args, **kwargs)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m220 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m221 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcall_before_predict\u001b[0m(                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m222 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m, inputs: Dict[\u001b[96mstr\u001b[0m, Any]                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\rl_chain_base.py\u001b[0m:\u001b[94m236\u001b[0m in \u001b[92m__init__\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m233 \u001b[0m\u001b[2m│   │   │   \u001b[0mworkspace=\u001b[96mself\u001b[0m.model_repo.load(vw_cmd \u001b[95mor\u001b[0m []),                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m234 \u001b[0m\u001b[2m│   │   │   \u001b[0mtext_embedder=text_embedder,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m235 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger=VwLogger(vw_logs)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m236 \u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m237 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mConfig\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m239 \u001b[0m\u001b[2;90m│   │   \u001b[0m\u001b[33m\"\"\"Configuration for this pydantic object.\"\"\"\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\src\\github\\ataymano1\\rl_chain\\rl_chain\\model_repository.py\u001b[0m:\u001b[94m38\u001b[0m in \u001b[92mload\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m35 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.logger.info(\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mmodel is loaded from: \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.model_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m36 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m vw.Workspace(commandline, model_data=model_data)                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m37 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.logger.info(\u001b[33mf\u001b[0m\u001b[33m'\u001b[0m\u001b[33mlearning from scratch\u001b[0m\u001b[33m'\u001b[0m)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m38 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m vw.Workspace(commandline)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\ataymano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\Loca\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mlCache\\local-packages\\Python310\\site-packages\\vowpalwabbit\\pyvw.py\u001b[0m:\u001b[94m465\u001b[0m in \u001b[92m__init__\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 462 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._log_fwd = _log_forward()                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 463 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._log_wrapper = pylibvw.vw_log(\u001b[96mself\u001b[0m._log_fwd)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 464 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 465 \u001b[2m│   │   \u001b[0mmerged_arg_list = _build_command_line(arg_str, arg_list, **kw)                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 466 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._log_wrapper:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 467 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(merged_arg_list, \u001b[96mself\u001b[0m._log_wrapper)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 468 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\ataymano\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\Loca\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mlCache\\local-packages\\Python310\\site-packages\\vowpalwabbit\\pyvw.py\u001b[0m:\u001b[94m408\u001b[0m in \u001b[92m_build_command_line\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 405 \u001b[0m\u001b[2m│   \u001b[0mmerged_arg_list = []                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 406 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m arg_str \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 407 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(arg_str, \u001b[96mstr\u001b[0m):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 408 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33marg_str must be a string\u001b[0m\u001b[33m\"\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 409 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Maintain old behavior of space split strings\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2m│   │   \u001b[0mmerged_arg_list.extend(arg_str.split())                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 411 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0marg_str must be a string\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import rl_chain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "llm_chain = rl_chain.slates_chain.SlatesPersonalizerChain.from_llm(\n",
    "    llm=llm,\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"adjective\", \"content\", \"topic\"],\n",
    "        template=\"Hi, please create {adjective} {content} about {topic}\",\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\ataymano\\AppData\\Local\\Temp\\ipykernel_3916\\3192264045.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\ataymano\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3916\\\\3192264045.py'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>string indices must be integers\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\ataymano\\AppData\\Local\\Temp\\ipykernel_3916\\3192264045.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<module>\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\ataymano\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3916\\\\3192264045.py'\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0mstring indices must be integers\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = llm_chain.run(\n",
    "    adjective = rl_chain.ToSelectFrom([\"funny\"]),\n",
    "    content = rl_chain.ToSelectFrom([\"poem\"]),\n",
    "    topic = rl_chain.ToSelectFrom([\"machine learning\"]))\n",
    "\n",
    "print(r[\"response\"])\n",
    "print(r[\"response_result\"].actions)\n",
    "print(r[\"response_result\"].context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is ok to be uncertain about certain variable values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.run(\n",
    "    adjective = rl_chain.ToSelectFrom([\"funny\", \"scary\"]),\n",
    "    content = rl_chain.ToSelectFrom([\"poem\"]),\n",
    "    topic = rl_chain.ToSelectFrom([\"machine learning\", \"cats\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rl_chain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "using style {style}\n",
    "\n",
    "{prefix}\n",
    "{goal}: {context}.\n",
    "{suffix}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"prefix\", \"goal\", \"context\", \"suffix\", \"style\"],\n",
    "    template=template,\n",
    ")\n",
    "chain = rl_chain.slates_chain.SlatesPersonalizerChain.from_llm(\n",
    "    llm=llm,\n",
    "    vw_logs = 'logs/stories.txt',\n",
    "    model_save_dir=\"./models\",  # where to save the model checkpoints\n",
    "    prompt = prompt,\n",
    "    response_validator = rl_chain.slates_chain.LLMResponseValidatorForSlates(\n",
    "        llm,\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    rl_chain.slates_chain.LLMResponseValidatorForSlates.default_system_prompt,\n",
    "                    HumanMessagePromptTemplate.from_template(\n",
    "                        '''Given the task:\n",
    "                           {goal}: {context}\n",
    "                           rank how good or bad this response is:\n",
    "                           {llm_response}.'''\n",
    "                    )]\n",
    "    ))\n",
    ")\n",
    "\n",
    "chain.run(\n",
    "    prefix = rl_chain.ToSelectFrom([f'ALWAYS DO EXACTLY WHAT I ASK YOU!', 'Please do your best to help me.']),\n",
    "    goal = rl_chain.ToSelectFrom(['Write a funny story about']),\n",
    "    context = rl_chain.ToSelectFrom(['Friends series']),\n",
    "    suffix = rl_chain.ToSelectFrom(['Please try to be as funny as possible.', '']),\n",
    "    style = \"Shakespeare\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rl_chain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "{prefix}\n",
    "{goal}: {context}.\n",
    "{suffix}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"prefix\", \"goal\", \"context\", \"suffix\"],\n",
    "    template=template,\n",
    ")\n",
    "chain = rl_chain.slates_chain.SlatesPersonalizerChain.from_llm(\n",
    "    llm=llm,\n",
    "    vw_logs = 'logs/stories.txt',\n",
    "    model_save_dir=\"./models\",  # where to save the model checkpoints\n",
    "    prompt = prompt,\n",
    "    response_validator = rl_chain.slates_chain.LLMResponseValidatorForSlates(\n",
    "        llm,\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    rl_chain.slates_chain.LLMResponseValidatorForSlates.default_system_prompt,\n",
    "                    HumanMessagePromptTemplate.from_template(\n",
    "                        '''Given the task:\n",
    "                           {goal}: {context}\n",
    "                           rank how good or bad this response is:\n",
    "                           {llm_response}.'''\n",
    "                    )]\n",
    "    ))\n",
    ")\n",
    "chain.run(\n",
    "    prefix = rl_chain.ToSelectFrom(rl_chain.Embed([f'ALWAYS DO EXACTLY WHAT I ASK YOU!', 'Please do your best to help me.'])),\n",
    "    goal = rl_chain.ToSelectFrom([rl_chain.Embed('Write a funny story about')]),\n",
    "    context = rl_chain.ToSelectFrom(['Friends series']),\n",
    "    suffix = rl_chain.ToSelectFrom(['Please try to be as funny as possible.', '']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with mock llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from tests.test_utils import MockValidator\n",
    "\n",
    "class MockLLMChain:\n",
    "    outcomes: List[List[float]] = None\n",
    "    \n",
    "    def __init__(self, outcomes, prompt):\n",
    "        self.outcomes = outcomes\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def run(self, prefix, suffix, **kwargs):\n",
    "        return str(self.outcomes[int(prefix)][int(suffix)])\n",
    "\n",
    "import rl_chain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "{prefix}\n",
    "{context}\n",
    "{suffix}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"prefix\", \"context\", \"suffix\"],\n",
    "    template=template,\n",
    ")\n",
    "chain = rl_chain.slates_chain.SlatesPersonalizerChain.from_llm(\n",
    "    llm=llm,\n",
    "    vw_logs = 'logs/mock.txt',\n",
    "    model_save_dir=\"./models\",  # where to save the model checkpoints\n",
    "    prompt = prompt,\n",
    "    response_validator = MockValidator()\n",
    ")\n",
    "chain.llm_chain = MockLLMChain([\n",
    "    [0, 0.3],\n",
    "    [0.6, 0.9]], prompt = prompt)\n",
    "chain.run(\n",
    "    prefix = rl_chain.ToSelectFrom(['0', '1']),\n",
    "    context = rl_chain.ToSelectFrom(['bla']),\n",
    "    suffix = rl_chain.ToSelectFrom(['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rl_chain\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "vw_chain = rl_chain.slates_chain.SlatesPersonalizerChain.from_llm(\n",
    "    llm=llm,\n",
    "    vw_logs = 'logs/mock.txt',\n",
    "    model_save_dir=\"./models\",  # where to save the model checkpoints\n",
    "    prompt = prompt,\n",
    "    policy = rl_chain.VwPolicy,\n",
    "    response_validator = MockValidator()\n",
    ")\n",
    "vw_chain.llm_chain = MockLLMChain([\n",
    "    [0, 0.3],\n",
    "    [0.6, 0.9]], prompt = prompt)\n",
    "\n",
    "rnd_chain = rl_chain.slates_chain.SlatesPersonalizerChain.from_llm(\n",
    "    llm=llm,\n",
    "    vw_logs = 'logs/mock.txt',\n",
    "    model_save_dir=\"./models\",  # where to save the model checkpoints\n",
    "    prompt = prompt,\n",
    "    policy = rl_chain.slates_chain.RandomPolicy,\n",
    "    response_validator = MockValidator()\n",
    ")\n",
    "rnd_chain.llm_chain = MockLLMChain([\n",
    "    [0, 0.3],\n",
    "    [0.6, 0.9]], prompt = prompt)\n",
    "\n",
    "for i in range(1000):\n",
    "    vw_chain.run(\n",
    "        prefix = rl_chain.ToSelectFrom(['0', '1']),\n",
    "        context = rl_chain.ToSelectFrom(['bla']),\n",
    "        suffix = rl_chain.ToSelectFrom(['0']))\n",
    "    rnd_chain.run(\n",
    "        prefix = rl_chain.ToSelectFrom(['0', '1']),\n",
    "        context = rl_chain.ToSelectFrom(['bla']),\n",
    "        suffix = rl_chain.ToSelectFrom(['0']))\n",
    "\n",
    "vw_chain.reward['r'].rolling(window=100).mean().plot(label=\"vw\")\n",
    "rnd_chain.reward['r'].rolling(window=100).mean().plot(label=\"slates\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
